\chapter{Introducción}
\label{introduccion}

\section{Motivación y objetivo general}
% TODO introducir inportancia de designaciones. comentar temas a tratar en cada capitulo ?
El testing basado en modelos (abreviado \textbf{MBT} del inglés \emph{``model based testing''}) es una de las técnicas de testing más prometedoras para la verificación de software crítico. Estas metodologías comienzan con un modelo formal o especificación del software, de la cual son generados los casos de prueba.
%La hipótesis fundamental detras del testing basado en modelos es que, un programa es correcto si verifica su especificación, entonces la especificación resulta una excelente fuente para obtener casos de prueba. %Una vez que los casos de prueba son derivados del modelo, estos son refinados al nivel del lenguaje de implementacion y ejecutados. Luego la salida del programa es abstraida al nivel de la especificacion y el modelo es usado nuevamente para verificar si el caso de prueba ha detectado un error.

Un caso particular del testing basado en modelos es el \emph{Test Template Framework} (\textbf{TTF}), descrito por Stocks y Carrington~\cite{stocks}, el cual utiliza como modelo de entrada especificaciones formales escritas en notación \emph{Z} y establece cómo generar casos de prueba para cada operación incluida en el modelo. Esta técnica genera descripciones lógicas, también en lenguaje Z, de los casos de prueba. El TTF propone en primera instancia obtener casos de prueba abstractos a partir de una especificación, cada uno de estos probará una alternativa funcional distinta del sistema a testear. Cada una de estas alternativas será expresada como un esquema Z llamado \emph{clase de prueba} y luego, a partir de las mismas, se generarán los casos de \emph{prueba concretos}.

En la figura~\ref{fig:intro_tcl} podemos observar, a modo de ejemplo, la clase de prueba \emph{Update\_SP\_4} junto al caso de prueba \emph{Update\_SP\_4\_TCASE} generados para testear la operación \emph{Update} que modela la actualización de una tabla de símbolos (en el capítulo~\ref{sec:ej-symbolTable} presentaremos la especificación completa).

\begin{figure}[H]
  \centering
  \begin{schema}{Update\_ SP\_ 4}\\
   st : SYM \pfun VAL \\
   s? : SYM \\
   v? : VAL 
  \where
   \dom st = \dom \{ s? \mapsto v? \}
  \end{schema}
  
  \begin{schema}{Update\_ SP\_ 4\_ TCASE}\\
   Update\_ SP\_ 4 
  \where
   st = \{ ( sym0 , val0 ) \} \\
   s? = sym0 \\
   v? = val0
 \end{schema}
 \caption{Clase y caso de prueba para operación Update.}
 \label{fig:intro_tcl}
\end{figure}

Por otro lado, es una practica común cuando se especifica formalmente un sistema, incluir \emph{designaciones}~\cite{jackson} entre elementos de la especificación (operaciones, esquemas de estado, variables, constantes, etc.) y elementos que refieran al dominio de la aplicación. En la figura~\ref{fig:intro_desig}, podemos ver algunas de las designaciones que deberían acompañar la especificación de la tabla de símbolos antes mencionada.

\begin{figure}[H]
  \begin{align*} 
    &Update && \approx \text{se intenta actualizar un símbolo en la tabla.} \\
    &dom~st && \approx \text{símbolos cargados en la tabla de símbolos.} \\
    &s? && \approx \text{símbolo a actualizar.} 
  \end{align*}
 \caption{Designaciones especificación SymbolTable.}
 \label{fig:intro_desig}
\end{figure}


El desarrollo de software crítico usualmente requiere de procesos independientes de validación y verificación. Estos procesos son llevados a cabo por expertos en el dominio de aplicación, quienes usualmente no poseen conocimientos técnicos, en nuestro caso en particular, necesitaríamos que la persona que realiza la verificación y validación sea capaz de leer Z para comprender lo que está siendo testeado. En estos casos, una descripción en lenguaje natural de cada caso de prueba debería acompañar a los mismos a fin de hacerlos accesibles para los expertos en el dominio. Por ejemplo, en la figura~\ref{fig:intro_tcl} mostramos una posible descripción para el caso de prueba del ejemplo anterior. 

\begin{figure}[H]
\textbf{Update\_SP\_4:} Se actualiza un símbolo en la tabla.  
  \begin{itemize}
   \item{Cuando:}
   \begin{itemize}
  	  \item{El símbolo a actualizar es el único símbolo cargado en la tabla de símbolos.}   
   \end{itemize}
  \end{itemize}
  \caption{Descripción en lenguaje natural para \emph{Update\_SP\_4}.}
  \label{fig:intro_tcl}
\end{figure}

Contar con una descripción en lenguaje natural como la previamente mencionada, sería de gran ayuda para que la persona a cargo de la validación y verificación comprenda lo que está siendo testeado.

En sistemas en los que hay una gran cantidad de casos de prueba, traducir manualmente  los mismos podría introducir errores humanos, reduciendo la calidad de las descripciones además de incrementar el costo total del testing.

El objetivo general de este trabajo, será entonces, desarrollar una solución para la generación automática de descripciones de casos de prueba generados por el TTF, trabajando fundamentalmente con la información contenida en las clases de prueba y haciendo uso de las designaciones antes mencionadas a fin de lograr una solución independiente del dominio de aplicación y del número de operaciones a testear. Para esto, utilizaremos técnicas de \emph{generación de lenguaje natural} (abreviado \textbf{NLG} del inglés  \emph{``natural language generation''}) que es el área del procesamiento de lenguaje natural que estudia la producción automática de textos en alguna lengua humana a partir de una representación computacional de la información. En particular, seguiremos la metodología más comúnmente aceptada para la construcción de sistemas de NLG, propuesta por Reiter y Dale~\cite{reiterdale}.

Como resultado de este trabajo también se realizó la implementación de un prototipo, desarrollado en Java e integrado a Fastest\footnote{http://www.flowgate.net/tools/} (una implementación del TTF desarrollada por Crstiá y Monetti~\cite{fastest1} capaz de generar casos de prueba a partir de una especificación Z) permitiendo la generación de descripciones de casos de prueba interactivamente desde la herramienta. 


\section{Antecedentes}

Se han hecho variados esfuerzos para producir versiones en lenguaje natural de especificaciones formales. Punshon \cite{punshon} usó un caso de estudio para presentar el sistema REVIEW \cite{review}. REVIEW parafraseaba automáticamente especificaciones desarrolladas con Metaview \cite{metaview}, un metasistema que facilita la construcción de entornos CASE para soportar tareas de especificación de software. Coscoy \cite{coscoy} desarrolló un mecanismo basado en la extracción de programas, para generar explicaciones de pruebas formales en el cálculo de construcciones inductivas, implementado en Coq \cite{coq}. Lavoie \cite{lavoie} presentó MODEX, una herramienta que genera descripciones personalizables de las relaciones entre clases en modelos orientados a objetos especificados en el estándar ODL \cite{odl}. Bertani \cite{bertani} describió un enfoque para la traducción de especificaciones formales escritas en una extensión de TRIO \cite{trio} en lenguaje natural controlado, transformando arboles sintácticos de TRIO en arboles sintácticos del lenguaje controlado.

Cristiá y Plüss \cite{cristiapluss} utilizaron métodos de generación de lenguaje natural basado en templates para la traducción de casos de prueba generados a partir de una especificación Z para un estándar aeroespacial. El trabajo anterior presenta una solución ad-hoc basada en templates, donde los templates utilizados son dependientes del dominio de aplicación y cantidad de operaciones. 

%Moya\cite{} extendió el trabajo anterior utilizando la información contenida en las designaciones\cite{asociaciones} (jackson entre los elementos de la especificación y los del domino de aplicación), trabajando exclusivamente con los casos de prueba.

Basado en el trabajo antes mencionado intentaremos desarrollar una solución independiente del dominio de aplicación y del número de operaciones del sistema. Para esto, trabajaremos fundamentalmente sobre las clases de prueba (que nos permitirán generar mejores descripciones), utilizando también la información contenida en las designaciones para lograr un resultado independiente del dominio.

\section{Alcance del trabajo}

Como mencionamos anteriormente, trabajaremos fundamentalmente a partir de clases de prueba generadas por el TTF escritas en notación Z.
Para esto, tendremos en cuenta un subconjunto del total de los operadores presentes en Z, pudiéndose en el futuro, ampliar o extender el mismo. Creemos que el conjunto de operadores escogidos es lo suficientemente abarcativo, permitiéndonos trabajar con una gran variedad de especificaciones y casos de pruebas generados a partir de las mismas.

En la figura~\ref{fig:alcance} podemos ver todos los operadores contemplados para este trabajo. Es decir, nuestro sistema de NLG deberá ser capaz de generar descripciones en lenguaje natural para todas las expresiones formadas a partir de estos operadores (incluyendo todas las expresiones que puedan surjir como combinaciones de los mismos).

\begin{figure}[H]
  \centering
        \begin{enumerate}[itemsep=0pt]
        \item =
        \item $\neq$
        \item $\in$
        \item $\notin$
        \item $\subset$
        \item $\subseteq$
        \item $\mapsto$
        \item $\{a,...,b\}$
        \item $\cup$
        \item $\cap$
        \item f~x (aplicación de función)
        \item $\dom$
        \item $\ran$
        \item +
        \item -
        \item *
        \item $\div$
        \item $\mod$
        \end{enumerate}
  \caption{Expresiones soportadas}
  \label{fig:alcance}
\end{figure}
