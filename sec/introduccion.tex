\chapter{Introducción}
\label{introduccion}

\section{Motivación y objetivo general}
% TODO introducir inportancia de designaciones. comentar temas a tratar en cada capitulo ?
El \textit{testing} basado en modelos (abreviado \textbf{MBT} del inglés \emph{``model based testing''}) es una de las técnicas de testing más prometedoras para la verificación de software crítico. Estas metodologías comienzan con un modelo formal (o especificación) del software a testear, y a partir del mismo son generados los casos de prueba.
%La hipótesis fundamental detras del testing basado en modelos es que, un programa es correcto si verifica su especificación, entonces la especificación resulta una excelente fuente para obtener casos de prueba. %Una vez que los casos de prueba son derivados del modelo, estos son refinados al nivel del lenguaje de implementacion y ejecutados. Luego la salida del programa es abstraida al nivel de la especificacion y el modelo es usado nuevamente para verificar si el caso de prueba ha detectado un error.

%TODO reescribir esto
Un caso particular del testing basado en modelos es el \emph{Test Template Framework} (abreviado \textbf{TTF}) descrito por Stocks y Carrington~\cite{stocks}. El TTF utiliza como modelo de entrada una especificación formal escrita en notación \emph{Z}~\cite{spivey} y establece cómo generar \emph{casos de prueba} para las operaciones incluidas en la especificación. 

Esta técnica genera descripciones lógicas, también en lenguaje Z, de los casos de prueba. El TTF propone en primera instancia obtener casos de prueba abstractos a partir de una especificación llamados \emph{clases de prueba} y luego, a partir de los mismos, generar los \emph{casos de prueba concretos}.

Por otro lado, el desarrollo de software crítico usualmente requiere de procesos independientes de validación y verificación. Estos procesos son llevados a cabo por expertos en el dominio de aplicación, quienes usualmente no poseen conocimientos técnicos para leer los casos de prueba (generados mediante el TTF, por ejemplo) y comprender lo que está siendo testeado con los mismos. En estos casos, una descripción en lenguaje natural de cada caso de prueba debería acompañar a los mismos a fin de hacerlos accesibles para los expertos en el dominio.  

Por ejemplo, en la figura~\ref{fig:intro_tcl} podemos observar, a modo ilustrativo, un caso de prueba (generado mediante el TTF) para la operación \emph{Update} perteneciente a una especificación para una tabla de símbolos y luego, en la figura~\ref{fig:intro_tcl1}, una posible descripción en lenguaje natural del mismo. Una tabla de símbolos es una estructura de datos creada y mantenida por un compilador con el fin de almacenar información (ubicación, ámbito, etc.) relativa a los distintos elemento del código fuente como: variables, nombres de funciones, objetos, etc. Ésta provee al menos dos operaciones: búsqueda e inserción (\textit{Update} en nuestro caso será la encargada de insertar y actualizar símbolos en la tabla). En la sección \ref{sec:ej-symbolTable} nos explayaremos más en detalle sobre el funcionamiento de una tabla de símbolos y presentaremos la especificación Z utilizada para el ejemplo.

\begin{figure}[H]
	\centering
  \begin{schema}{Update\_ SP\_ 4\_ TCASE}\\
   Update\_ SP\_ 4 
  \where
   st = \{ ( sym0 , val0 ) \} \\
   s? = sym0 \\
   v? = val0
 \end{schema}
 \caption{Caso de prueba para operación \emph{Update}.}
  \label{fig:intro_tcl}
\end{figure}
 
\begin{figure}[H]
 \begin{tcolorbox}[colback=gray!5!white,colframe=gray!50!black,
  colbacktitle=gray!75!black,title=Update\_SP\_4]
  Se actualiza un símbolo en la tabla, cuando:
     \begin{itemize}
  	    \item[--]{El símbolo a actualizar es el único símbolo cargado en la tabla de símbolos.}
     \end{itemize}
 \end{tcolorbox}
 \caption{Posible descripción en lenguaje natural para \emph{Update\_SP\_4}.}
 \label{fig:intro_tcl1}
\end{figure}

Contar con una descripción en lenguaje natural como la de la figura \ref{fig:intro_tcl1}, sería de gran ayuda para que la persona a cargo de la validación y verificación comprenda lo que está siendo testeado y además, fundamentalmente, para conectar la especificación del caso de prueba con lo que esto significa en la implementación.


En sistemas en los que hay una gran cantidad de casos de prueba, traducir manualmente los mismos podría introducir errores humanos, reduciendo la calidad de las descripciones además de incrementar el costo del testing.

El objetivo de este trabajo, será entonces, desarrollar una solución para la generación automática de descripciones para los casos de prueba generados por el TTF. Para esto, utilizaremos técnicas de \emph{generación de lenguaje natural} (abreviado \textbf{NLG} del inglés  \emph{``natural language generation''}). En particular, seguiremos la metodología más comúnmente aceptada para la construcción de sistemas de NLG, propuesta por Reiter y Dale~\cite{reiter_dale}. Trabajaremos principalmente con las \emph{clases de prueba}, ya que estas son las que contienen la información referente a las alternativas funcionales que se intentan testear mediante cada \emph{caso de prueba} generado. Además deseamos idear una solución independiente del número de operaciones del modelo así como del dominio de aplicación del mismo. Para esto, junto con la utilización de técnicas de NLG, haremos uso de la información contenida en las designaciones~\cite{jackson} (asociaciones entre los elementos de la especificación y elementos que refieren al dominio de la aplicación) que deberían acompañar la especificación formal. 


Como resultado de este trabajo también se realizará la implementación de un prototipo, a desarrollarse en lenguaje Java e integrarse a \emph{Fastest}\footnote{\url{http://www.fceia.unr.edu.ar/~mcristia/fastest-1.6.tar.gz}} (una implementación del TTF desarrollada por Crstiá y Monetti~\cite{fastest1} capaz de generar casos de prueba a partir de una especificación Z) permitiendo la generación de descripciones de casos de prueba interactivamente desde la herramienta. 

\section{Antecedentes}

Se han hecho variados esfuerzos para producir versiones en lenguaje natural de especificaciones formales. Punshon \cite{punshon} usó un caso de estudio para presentar el sistema REVIEW \cite{review}. REVIEW parafraseaba automáticamente especificaciones desarrolladas con Metaview \cite{metaview}, un meta-sistema que facilita la construcción de entornos CASE (\textit{Computer Aided Software Engineering}) para soportar tareas de especificación de software. Coscoy \cite{coscoy} desarrolló un mecanismo basado en la extracción de programas, para generar explicaciones de pruebas formales en el cálculo de construcciones inductivas, implementado en Coq \cite{coq}. Lavoie \cite{lavoie} presentó MODEX, una herramienta que genera descripciones personalizables de las relaciones entre clases en modelos orientados a objetos especificados en el estándar ODL \cite{odl}. Bertani \cite{bertani} describió un enfoque para la traducción de especificaciones formales escritas en una extensión de TRIO \cite{trio} en lenguaje natural controlado, transformando arboles sintácticos de TRIO en arboles sintácticos del lenguaje controlado.  

Cristiá y Plüss \cite{cristia_pluss} un método de generación de lenguaje natural basado en \textit{templates} para la traducción de casos de prueba generados a partir de una especificación Z para un estándar aeroespacial. El trabajo presenta una solución ad-hoc basada en \textit{templates}, donde los \textit{templates} utilizados son dependientes del dominio de aplicación y de la cantidad de operaciones en la especificación. Basado en este trabajo, intentaremos desarrollar una solución independiente del dominio de aplicación y del número de operaciones del sistema. Para esto, trabajaremos fundamentalmente sobre las clases de prueba (que nos permitirán generar mejores descripciones), utilizando también la información contenida en las designaciones para lograr un resultado independiente del dominio.

\section{Alcance del trabajo}

Como mencionamos anteriormente, trabajaremos fundamentalmente a partir de clases de prueba generadas por el TTF escritas en notación Z.
Para esto, tendremos en cuenta un subconjunto del total de los operadores presentes en Z, pudiéndose en el futuro ampliar o extender el mismo. Creemos que el conjunto de operadores escogidos es lo suficientemente abarcativo, permitiéndonos trabajar con una gran variedad de especificaciones y casos de pruebas generados a partir de las mismas.

En la figura~\ref{fig:alcance} podemos ver todos los operadores contemplados para este trabajo. Es decir, nuestro sistema de NLG deberá ser capaz de generar descripciones en lenguaje natural para todas las expresiones formadas a partir de estos operadores (incluyendo todas las expresiones que puedan surgir como combinaciones de los mismos).

\begin{figure}[H]
  \fbox{\begin{minipage}{13 cm}
        \begin{enumerate}[itemsep=0pt]
        \item =
        \item $\neq$
        \item $\in$
        \item $\notin$
        \item $\subset$
        \item $\subseteq$
        \item $\mapsto$
        \item $\{a,...,b\}$
        \item $\cup$
        \item $\cap$
        \item f~x (aplicación de función)
        \item $\dom$
        \item $\ran$
        \item +
        \item -
        \item *
        \item $\div$
        \item $mod$
        \end{enumerate}
  \end{minipage}}
  \caption{Expresiones soportadas}
  \label{fig:alcance}
\end{figure}

\subsection{Estructura de la tesina}
En este capítulo presentamos los objetivos principales para este trabajo. Establecimos cómo uno de los estos, lograr una solución superadora al trabajo realizado por Cristiá y Plüss \cite{cristia_pluss} (único hasta el el momento en trabajar sobre generación de lenguaje natural para Z y el TTF). Puntualmente, a diferencia del anterior, nuestro objetivo será lograr una generación de descripciones en lenguaje natural independiente del dominio de aplicación y de la cantidad de clases y casos de pruebas.

En el próximo capítulo introduciremos conceptos básicos acerca del \textit{test template framework} fundamentales para el desarrollo de este trabajo. Luego, en el capítulo \ref{cap:nlg_intro}, presentaremos la metodología a utilizar para diseñar y construir nuestro sistema de NLG. En el capítulo \ref{cap:corpus} realizaremos un análisis de requerimientos en base al corpus de datos recolectado, que resultará de vital importancia para el desarrollo de las distintas tareas que deberá realizar nuestro sistema - las cuales estudiaremos en profundidad en los capítulos \ref{cap:document_planning}, \ref{cap:microplanning} y \ref{cap:realization}. En el capítulo \ref{cap:implementacion} veremos los aspectos más relevantes de la implementación realizada y finalmente en el capítulo \ref{cap:conclusion} presentaremos las conclusiones de esta tesina, así como también posibles trabajos futuros.